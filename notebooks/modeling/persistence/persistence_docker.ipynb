{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence model\n",
    "\n",
    "You remember your professor of the Time Series class. \n",
    "\n",
    "Don't build a crazy model before trying with persistence. A baseline is always valuable: sometimes it provides good enough results, but it always sets the level for more complex approaches.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Simplification.</b> \n",
    "\n",
    "There is absolutely no good reason to go through the following complex procedure just to build a persistence baseline: the `.shift()` method of `pandas.Series` makes the job. However, we will use the persistence model to demostrate how to create a model with custom code and container.\n",
    "</div>\n",
    "\n",
    "You heard from your fellow data scientist Marta about a cool library for time series forecasting, built on top of sklearn and you want to try it out. So, you start by installing sktime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ml.m5.xlarge' is included in the AWS Free Tier\n",
    "INSTANCE_TYPE = 'ml.m5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sktime --user\n",
    "! pip install pandas s3fs --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, restart the kernel if this is the first time you run this notebook.\n",
    "\n",
    "This is necessary to ensure that we can actually import the libraries we've just installed in the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the default size for matplotlib plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = prefix = 'persistence-baseline'\n",
    "\n",
    "boto3_session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "region = boto3_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preparation\n",
    "You figure the process of building your docker image. To start, you create the ECR (Elastic Container Registry) repository. Then, you build the Docker image with the train and inference code, and finally you push it to such repository.    \n",
    "\n",
    "Fortunately, your favourite ML Engineers, Matteo and Gabriele, have already done it for you, and you can use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$image_name\" \"$region\"\n",
    "# chmod 755 build_push.sh\n",
    "# ./build_push.sh $1 $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! docker image ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = \"919788038405.dkr.ecr.eu-west-1.amazonaws.com/persistence-baseline:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data gathering\n",
    "The data processing pipeline created by Matteo and Gabriele deposits the final dataset in a conventional location on S3.\n",
    "In order to retrieve the data to crunch, you first load the S3 object. \n",
    "\n",
    "With `pandas`, the integration is immediate: S3 URI are resolved as if they were file paths.\n",
    "\n",
    "You also create some objects that will be useful throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_s3_path = \"s3://public-workshop/normalized_data/processed/2006_2022_data.parquet\"\n",
    "raw_df = pd.read_parquet(raw_data_s3_path)\n",
    "resampled_df = raw_df.resample('D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW = '2019-12-31 23:59'\n",
    "TRAIN_END = '2017-12-31 23:59'\n",
    "\n",
    "load_df = resampled_df[:NOW].copy()\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload on S3\n",
    "SageMaker train jobs retrieve data from S3: you thus need to upload the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prefix = \"amld22-workshop-sagemaker\"\n",
    "local_train_path = \"persistence_train.parquet\"\n",
    "\n",
    "s3_train_path = f's3://{sagemaker_bucket}/{main_prefix}/data/modelling/{prefix}/train.parquet'\n",
    "load_df.to_parquet(s3_train_path)\n",
    "print(f\"Data uploaded to: {s3_train_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create estimator & Train\n",
    "Then, you can use your custom docker image to train the persistence model - yeah, you smile when you think about \"training persistence\".\n",
    "\n",
    "Yet, you have a final look to your `persistence/train.py` and `persistence/serve.py` files and you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    hyperparameters={\n",
    "        \"strategy\": \"last\",\n",
    "        \"sp\": 365,\n",
    "    }\n",
    ")\n",
    "\n",
    "sk_model.fit({\n",
    "    \"training\": s3_train_path,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "Using the facility of AWS SageMaker, you deploy the model to a managed endpoint.\n",
    "\n",
    "SageMaker then uses the `persistence/serve.py` module to spin up a Flask server and make predictions.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Simplification.</b> \n",
    "\n",
    "The Flask development server we use is **NOT** a production server, please make sure to set up a more robust and secure serving method when deploying to production. For example, have a look at the inference approach of: https://github.com/aws/amazon-sagemaker-examples/tree/main/advanced_functionality/scikit_bring_your_own/container\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "You use the deployed API to predict on the test set.\n",
    "\n",
    "Results are not that bad, but there is definitely room for improvements. \n",
    "\n",
    "You smile, and open Google Scholar to look for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = load_df[TRAIN_END:].Load\n",
    "prediction_index = y_true.index\n",
    "fh_absolute = ForecastingHorizon(prediction_index, is_relative=False)\n",
    "\n",
    "# Predict using the deployed model\n",
    "y_pred = sk_predictor.predict(fh_absolute)\n",
    "y_pred_series = pd.Series(y_pred.values(), index=prediction_index)\n",
    "\n",
    "# Compute MAPE\n",
    "naive_mape = mean_absolute_percentage_error(y_true, y_pred_series)\n",
    "\n",
    "# Plot results\n",
    "plt.title(f\"Persistence | MAPE: {100 * naive_mape:.2f} %\")\n",
    "plt.plot(y_true, label='Actual')\n",
    "plt.plot(y_pred_series, label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid(0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "If youâ€™re ready to be done with this notebook, please run the cells below with `CLEANUP = True`. \n",
    "\n",
    "This will remove the model and hosted endpoint to avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEANUP:\n",
    "    sk_predictor.delete_model()\n",
    "    sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
