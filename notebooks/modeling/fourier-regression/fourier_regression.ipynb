{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier regression\n",
    "\n",
    "The baseline was quite unsatisfactory. You can do better than this.\n",
    "\n",
    "Many methods for long-term forecasting aim at identifying and reconstructing the trend and seasonal structure of the series.\n",
    "When sesonal components are important, as in this case, a common approach is [Fourier regression](https://otexts.com/fpp3/useful-predictors.html#fourier-series).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Simplification.</b> \n",
    "\n",
    "There are many academic papers and book chapters about the application of Fourier regression for time series forecasting. Here, a simple method will provide a good case study to introduce SageMaker algorithms.\n",
    "    \n",
    "The interested reader may refer to [A. Incremona, Machine Learning methods for long and short term energy demand forecasting](https://iris.unipv.it/retrieve/handle/11571/1436355/470615/Incremona_PhD_Thesis.pdf), [A. Incremona, G. De Nicolao, Spectral Characterization of the Multi-Seasonal Component of the Italian Electric Load: A LASSO-FFT Approach](https://ieeexplore.ieee.org/abstract/document/8734852), and [A. Guerini, G. De Nicolao, Long-term electric load forecasting: A torus-based approach](https://ieeexplore.ieee.org/abstract/document/7330957).\n",
    "</div>\n",
    "\n",
    "Here, you opt for a simple unregularized linear model:\n",
    "$$\n",
    "y_t = \\mu + \\kappa t + \\sum_{i=1}^n\\alpha_i\\sin(2\\pi\\frac{i}{7}t) + \\beta_i\\cos(2\\pi\\frac{i}{7}t) + \\sum_{j=1}^m\\gamma_i\\sin(2\\pi\\frac{j}{365.25}t) + \\delta_j\\sin(2\\pi\\frac{j}{365.25}t) + \\tau_t\n",
    "$$\n",
    "where:\n",
    "- the terms $\\mu + \\kappa t$ model a linear trend\n",
    "- $\\tau_t$ is a dummy variable, which takes value 1 when date $t$ is a holiday\n",
    "- the sums $\\sum_{i=1}^n\\alpha_i\\sin(2\\pi\\frac{i}{7}t) + \\beta_i\\cos(2\\pi\\frac{i}{7}t) + \\sum_{j=1}^m\\gamma_i\\sin(2\\pi\\frac{j}{365.25}t)$  model the weekly and yearly periodicity\n",
    "\n",
    "The parameters of the model are $\\mu$, $\\kappa$, $\\{\\alpha_i\\}$, $\\{\\beta_i\\}$, $\\{\\gamma_j\\}$, $\\{\\delta_j\\}$, which can all be trained by least squares. The hyperparameters are $n$ and $m$, which can be chosen by cross-validation.\n",
    "\n",
    "Moreover, in such models it is common to log-transform the target variable, in order to stabilize the variance of the series. Therefore, another candidate model is  \n",
    "$$\n",
    "\\log y_t = \\mu + \\kappa t + \\sum_{i=1}^n\\alpha_i\\sin(2\\pi\\frac{i}{7}t) + \\beta_i\\cos(2\\pi\\frac{i}{7}t) + \\sum_{j=1}^m\\gamma_i\\sin(2\\pi\\frac{j}{365.25}t) + \\delta_j\\sin(2\\pi\\frac{j}{365.25}t) + \\tau_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Unfortunately, you soon discover that the default packages installed in SageMaker Studio are quite outdated. \n",
    "Therefore, after some Googling, you resort to upgrade `sagemaker-experiments`, `s3fs`, and `pandas`.\n",
    "\n",
    "Moreover, you install `holidays` to ease feature engineering.\n",
    "\n",
    "The warnings and errors raised by package installation are not a concern for this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sagemaker experiments\n",
    "!pip install sagemaker-experiments --upgrade\n",
    "\n",
    "# Required for feature engineering\n",
    "!pip install holidays\n",
    "\n",
    "# To read data from S3\n",
    "! pip install pandas s3fs --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, restart the kernel if this is the first time you run this notebook.\n",
    "\n",
    "This is necessary to ensure that we can actually import the libraries we've just installed in the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ml.m5.xlarge' is included in the AWS Free Tier\n",
    "INSTANCE_TYPE = 'ml.m5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.tracker import Tracker\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the default size for matplotlib plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data gathering\n",
    "The data processing pipeline created by Matteo and Gabriele deposits the final dataset in a conventional location on S3.\n",
    "In order to retrieve the data to crunch, you first load the S3 object. \n",
    "\n",
    "With `pandas`, the integration is immediate: S3 URI are resolved as if they were file paths.\n",
    "\n",
    "You also create some objects that will be useful throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_bucket = sagemaker_session.default_bucket()\n",
    "main_prefix = \"amld22-workshop-sagemaker\"\n",
    "\n",
    "raw_data_s3_path = \"s3://public-workshop/normalized_data/processed/2006_2022_data.parquet\"\n",
    "raw_df = pd.read_parquet(raw_data_s3_path)\n",
    "resampled_df = raw_df.resample('D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are at the beginning the January 2020. So, you can only see the data until the end of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW = '2019-12-31 23:59'\n",
    "TRAIN_END = '2017-12-31 23:59'\n",
    "\n",
    "load_df = resampled_df[:NOW].copy()\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preparation\n",
    "To perform a Fourier regression, you need proper inputs. Therefore, you build a new dataset.\n",
    "\n",
    "You add the trend and holiday dummy, then you build the Fourier harmonics.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Simplification.</b> \n",
    "\n",
    "In the real world, a good practice would be to choose the number of harmonics with data-driven methods: cross-validation is one, LASSO is another. If the latter is chosen, information criteria or cross-validation is needed to pick the most effective value of the regularizazion parameter. Here, we do not show how the hyperparameters were chosen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_harmonics = 5\n",
    "yearly_harmonics = 20\n",
    "\n",
    "\n",
    "def create_dataset_for_regression(dates: pd.DatetimeIndex, weekly_harmonics: int,\n",
    "                                  yearly_harmonics: int) -> pd.DataFrame:\n",
    "    date_origin = pd.to_datetime('2000-01-01')\n",
    "    holiday_cal = holidays.Italy()\n",
    "    regression_df = pd.DataFrame(index=dates)\n",
    "    regression_df['trend'] = (dates - date_origin).days\n",
    "    regression_df['holiday'] = dates.to_series().apply(lambda s: s in holiday_cal).astype(int)\n",
    "    for i in range(1, weekly_harmonics + 1):\n",
    "        regression_df[f'sin_7_{i}'] = np.sin(2 * np.pi * i / 7 * regression_df['trend'])\n",
    "        regression_df[f'cos_7_{i}'] = np.cos(2 * np.pi * i / 7 * regression_df['trend'])\n",
    "    for i in range(1, yearly_harmonics + 1):\n",
    "        regression_df[f'sin_365_{i}'] = np.sin(2 * np.pi * i / 365.25 * regression_df['trend'])\n",
    "        regression_df[f'cos_365_{i}'] = np.cos(2 * np.pi * i / 365.25 * regression_df['trend'])\n",
    "    return regression_df\n",
    "\n",
    "\n",
    "regression_data_df = load_df.join(create_dataset_for_regression(load_df.index, weekly_harmonics, yearly_harmonics))\n",
    "regression_train_df, regression_test_df = regression_data_df[:TRAIN_END], regression_data_df[TRAIN_END:]\n",
    "regression_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload on S3\n",
    "SageMaker train jobs retrieve data from S3: you thus need to upload the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_path = f's3://{sagemaker_bucket}/{main_prefix}/data/modelling/fourier-regression/train.parquet'\n",
    "s3_test_path = f's3://{sagemaker_bucket}/{main_prefix}/data/modelling/fourier-regression/test.parquet'\n",
    "\n",
    "regression_train_df.to_parquet(s3_train_path)\n",
    "regression_test_df.to_parquet(s3_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature store setup\n",
    "\n",
    "You do not want to recompute all the feature every time you want to train and, most notably, make predictions.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note.</b> \n",
    "\n",
    "Actually, our features are very easy and quick to compute. So, it would not be inefficient to just create the proper dataset at inference time. But let's pretend this is not the case.\n",
    "</div>\n",
    "\n",
    "Therefore, you resort to the AWS SageMaker Feature Store. You compute the features once, up to a future as far as you think necessary, and you save the result in the feature store. At inference time, you can easily retrieve the records from the feature store, although this comes with some limitations - for instance, you will not be able to predict more than 100 samples at the same time.\n",
    "\n",
    "Feel free to check out more about the feature store on the [AWS documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group: FeatureGroup) -> None:\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"Feature Group {feature_group.name} successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "date_feature_name = 'date'\n",
    "event_time_feature_name = 'event_time'\n",
    "\n",
    "feature_dates = pd.date_range('2000-01-01', '2029-12-31', freq='D')\n",
    "feature_df = create_dataset_for_regression(feature_dates, weekly_harmonics, yearly_harmonics)\n",
    "feature_df[date_feature_name] = pd.Series(feature_df.index.strftime('%Y-%m-%d'), dtype='string', index=feature_df.index)\n",
    "feature_df[event_time_feature_name] = pd.Series(round(time.time()), dtype='float', index=feature_df.index)\n",
    "\n",
    "feature_group = FeatureGroup(name='load-forecasting', sagemaker_session=sagemaker_session)\n",
    "\n",
    "try:\n",
    "    feature_group.load_feature_definitions(data_frame=feature_df.reset_index(drop=True))\n",
    "    feature_group.create(\n",
    "        s3_uri=f\"s3://{sagemaker_bucket}/{main_prefix}/feature-store/{feature_group.name}\",\n",
    "        record_identifier_name=\"date\",\n",
    "        event_time_feature_name=\"event_time\",\n",
    "        role_arn=sagemaker.get_execution_role(),\n",
    "        enable_online_store=True,\n",
    "    )\n",
    "\n",
    "    wait_for_feature_group_creation_complete(feature_group)\n",
    "    feature_group.ingest(data_frame=feature_df, max_workers=3, wait=True)\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceInUse':\n",
    "        print(f'Feature group {feature_group.name} already exists. Skipping creation...')\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "featurestore_client = boto_session.client(service_name='sagemaker-featurestore-runtime')\n",
    "featurestore_client.get_record(FeatureGroupName=feature_group.name, RecordIdentifierValueAsString='2018-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn training\n",
    "\n",
    "You then turn to the training step.\n",
    "\n",
    "We will use the script `fourier_regression_train.py`.\n",
    "\n",
    "The sklearn estimator requires an external script: when the `fit()` method of the estimator is called, the script is injected into an AWS-managed container, and the python script gets executed.\n",
    "\n",
    "The hyperparameters of the estimator are passed to the script as command-line parameters, while the train and test dataset are injected into the container, in locations defined by conventional environment variables (`SM_CHANNEL_TRAIN` and `SM_CHANNEL_TEST`).\n",
    "\n",
    "The trained model should be dumped to a third conventional location, available in the environment variable `SM_MODEL_DIR`, so that it can later be retrieved for inference.\n",
    "\n",
    "More information about training sklearn models on the [AWS documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "Log transformation or no log transformation?\n",
    "\n",
    "Why not trying both!\n",
    "\n",
    "In order to try out different model configurations and compare the results, you adopt the model registry. For each trial you can log input, parameters, performance metrics, trained models, and many other data. \n",
    "\n",
    "Using an experiment registry and proper code and data versioning systems is the best way to ensure reproducibility and accountability of results.\n",
    "\n",
    "Experiments are organized hierarchically in trials and components. Automatic charts are created for metrics, even though they are best suited for Deep Learning models (more on this later). \n",
    "\n",
    "You will use the results of the experiments to inspect the goodness of models, and you will leverage the SDK to automatically choose the best one to deploy.\n",
    "\n",
    "More on the experiment registry on the [AWS documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name: str, experiment_description: str) -> Experiment:\n",
    "    experiment = None\n",
    "    for exp in Experiment.list():\n",
    "        if exp.experiment_name == experiment_name:\n",
    "            return Experiment.load(experiment_name=experiment_name)\n",
    "\n",
    "    if experiment is None:\n",
    "        return Experiment.create(experiment_name=experiment_name, description=experiment_description)\n",
    "\n",
    "\n",
    "fourier_experiment = get_or_create_experiment(\n",
    "    experiment_name=\"load-forecasting-fourier-regression\",\n",
    "    experiment_description=\"Fourier regression for Italian load forecasting\"\n",
    ")\n",
    "\n",
    "with Tracker.create(display_name='Preprocessing') as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"weekly_harmonics\": weekly_harmonics,\n",
    "        \"yearly_harmonics\": yearly_harmonics,\n",
    "    })\n",
    "    preprocessing_trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn model fit\n",
    "Everything is set and ready. You can run the training job.\n",
    "\n",
    "The job runs on ad-hoc managed virtual machines on AWS. You think about running the first trials in local mode, but you realize it works only on SageMaker Notebook, not on SageMaker Studio. What is the point, then? What can possibly go wrong?\n",
    "\n",
    "You run two trials, both with and without the logarithmic transformation. Inspecting the logs, you note the metrics: they are extracted using suitable regex and reported SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log_transform_target in [0, 1]:\n",
    "    fourier_trial = Trial.create(\n",
    "        trial_name=f\"linear-regression-{datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')}\",\n",
    "        experiment_name=fourier_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    )\n",
    "\n",
    "    fourier_trial.add_trial_component(preprocessing_trial_component)\n",
    "\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='fourier_regression.py',\n",
    "        framework_version=\"0.23-1\",\n",
    "        instance_type=INSTANCE_TYPE,\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        hyperparameters={\"log_transform_target\": log_transform_target},\n",
    "        metric_definitions=[\n",
    "            {\"Name\": \"train:mape\", \"Regex\": \"Train MAPE: (.*?);\"},\n",
    "            {\"Name\": \"train:mae\", \"Regex\": \"Train MAE: (.*?);\"},\n",
    "            {\"Name\": \"train:rmse\", \"Regex\": \"Train RMSE: (.*?);\"},\n",
    "            {\"Name\": \"test:mape\", \"Regex\": \"Test MAPE: (.*?);\"},\n",
    "            {\"Name\": \"test:mae\", \"Regex\": \"Test MAE: (.*?);\"},\n",
    "            {\"Name\": \"test:rmse\", \"Regex\": \"Test RMSE: (.*?);\"},\n",
    "        ],\n",
    "        enable_sagemaker_metrics=True,\n",
    "    )\n",
    "\n",
    "    sklearn_estimator.fit(\n",
    "        inputs={\n",
    "            \"train\": s3_train_path,\n",
    "            \"test\": s3_test_path\n",
    "        },\n",
    "        experiment_config={\n",
    "            \"ExperimentName\": fourier_experiment.experiment_name,\n",
    "            \"TrialName\": fourier_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment review\n",
    "When the job ends, you inspect the experiment results. In particular, you care about the train and test Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "The model with log transformation is only marginally better. You decide to promote it anyway and go on with the deployment of the serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    experiment_name=fourier_experiment.experiment_name,\n",
    "    sort_by=\"metrics.test:mape.max\",\n",
    "    sort_order=\"Ascending\",\n",
    "    metric_names=[\"train:mape\", \"test:mape\"],\n",
    "    parameter_names=[\"log_transform_target\"],\n",
    "    search_expression={\n",
    "        \"Filters\": [\n",
    "            {\n",
    "                \"Name\": \"DisplayName\",\n",
    "                \"Operator\": \"Equals\",\n",
    "                \"Value\": \"Training\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "trial_component_analytics.dataframe()[['TrialComponentName', 'train:mape - Avg', 'test:mape - Avg', 'log_transform_target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model selection\n",
    "Using the SageMaker Experiments SDK you find the model with the lowest MAPE, and you create an SKLearn model for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling best based on sort in the analytics/dataframe so first is best....\n",
    "best_trial_component_name = trial_component_analytics.dataframe().iloc[0][\"TrialComponentName\"]\n",
    "best_trial_component = TrialComponent.load(best_trial_component_name)\n",
    "\n",
    "best_sklearn_estimator = SKLearnModel(\n",
    "    model_data=best_trial_component.output_artifacts[\"SageMaker.ModelArtifact\"].value,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    entry_point='fourier_regression.py',\n",
    "    env={\"log_transform_target\": str(int(best_trial_component.parameters[\"log_transform_target\"]))},\n",
    "    # parameters are saved as float by default, but the training script required int\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version=\"0.23-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "Using the facility of AWS SageMaker, you deploy the model to a managed endpoint.\n",
    "\n",
    "On inference, the functions `model_fn` and `input_fn` of the `fourier_regression.py` module will be called and will allow the trained model to be fed with new data.\n",
    "Due to limitations on the online Feature Store, only 100 samples can be predicted on each call of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_predictor = best_sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    serializer=sagemaker.serializers.JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Finally, you use the deployed model to perform some predictions. \n",
    "\n",
    "You use the sklearn estimator client, but your colleagues can call the API using any REST client. \n",
    "\n",
    "The integration of the feature store makes the API agnostic to the features: only a list of dates is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual_series = regression_test_df.Load.iloc[:100]\n",
    "\n",
    "request_data = {'dates': regression_test_df.index[:100].strftime('%Y-%m-%d').tolist()}\n",
    "test_predictions = sklearn_predictor.predict(request_data)\n",
    "test_prediction_series = pd.Series(test_predictions, index=regression_test_df.index[:100])\n",
    "\n",
    "fourier_mape = mean_absolute_percentage_error(test_actual_series, test_prediction_series)\n",
    "\n",
    "plt.title(f\"Fourier regression | MAPE: {100 * fourier_mape:.2f} %\")\n",
    "plt.plot(regression_test_df.Load.iloc[:100], label='actual')\n",
    "plt.plot(test_prediction_series, label='prediction')\n",
    "plt.grid(0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very tough year\n",
    "Time flies: we are at the end of March 2020, and the world has changed.\n",
    "\n",
    "Probably the least damaging effect of the pandemic, your models do not work anymore. You backtest your last long-term model on the period from January to March 2020, and the results are depressing. The MAPE skyrockets to unacceptable levels.\n",
    "\n",
    "No long-term approach can account for the disruption caused by lockdowns: it is time to change approach. If you want to be accurate in a fast-changing environment, you have to resort to short-term models.\n",
    "\n",
    "However, a worrying idea refuses to leave your mind. If a sudden, unexpected event like an epidemic happens, it is reasonable to assume all the models of human behaviours will be impacted. But if changes happen slowly, how can we capure them? How can we make sure that our models are always reliable and effective?\n",
    "\n",
    "You walk away from your PC. Next time you will meet your good friends and fellow Data Scientists Marta and Gabriele, you will have an interesting topic to discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dates = pd.date_range('2020-01-06', '2020-03-31', freq='D')\n",
    "covid_predictions = sklearn_predictor.predict({'dates': covid_dates.strftime('%Y-%m-%d').tolist()})\n",
    "covid_prediction_series = pd.Series(covid_predictions, index=covid_dates)\n",
    "covid_actual_series = resampled_df.loc[covid_dates, :].Load\n",
    "\n",
    "covid_mape = mean_absolute_percentage_error(covid_actual_series, covid_prediction_series)\n",
    "\n",
    "plt.title(f\"Fourier regression | Covid MAPE: {100 * covid_mape:.2f} %\")\n",
    "plt.plot(covid_actual_series, label='actual')\n",
    "plt.plot(covid_prediction_series, label='prediction')\n",
    "plt.legend()\n",
    "plt.grid(0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_prediction_df = pd.DataFrame({'actual': covid_actual_series, 'predicted': covid_prediction_series})\n",
    "rolling_mape_df = pd.DataFrame(\n",
    "    {'rolling_mape': map(lambda w: mean_absolute_percentage_error(w[\"actual\"], w[\"predicted\"]),\n",
    "                         covid_prediction_df.rolling(7, method=\"table\"))},\n",
    "    index=covid_prediction_df.index\n",
    ")\n",
    "plt.plot(rolling_mape_df.rolling_mape)\n",
    "plt.title('Rolling MAPE (7-day window)')\n",
    "plt.grid(0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "If you’re ready to be done with this notebook, please run the cells below with `CLEANUP = True`. \n",
    "\n",
    "This will remove the model, hosted endpoint, and all the experiments you created to avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEANUP:\n",
    "    sklearn_predictor.delete_model()\n",
    "    sklearn_predictor.delete_endpoint()\n",
    "    feature_group.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_sme_sdk(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(trial_component_name=trial_component_summary.trial_component_name)\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                tc.delete()\n",
    "            except:\n",
    "                continue\n",
    "            time.sleep(.5)  # to prevent throttling\n",
    "        trial.delete()\n",
    "        experiment_name = experiment.experiment_name\n",
    "    experiment.delete()\n",
    "\n",
    "\n",
    "if CLEANUP:\n",
    "    for e in Experiment.list():\n",
    "        print(f\"Deleting {e.experiment_name}...\")\n",
    "        experiment_to_cleanup = Experiment.load(experiment_name=e.experiment_name)\n",
    "        cleanup_sme_sdk(experiment_to_cleanup)\n",
    "        print(f\"Deleted {e.experiment_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
